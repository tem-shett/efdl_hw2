{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-16T01:53:43.370898Z",
     "iopub.status.busy": "2026-02-16T01:53:43.370353Z",
     "iopub.status.idle": "2026-02-16T01:53:43.885925Z",
     "shell.execute_reply": "2026-02-16T01:53:43.885105Z",
     "shell.execute_reply.started": "2026-02-16T01:53:43.370866Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'efdl_hw2'...\n",
      "remote: Enumerating objects: 88, done.\u001b[K\n",
      "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
      "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
      "remote: Total 88 (delta 52), reused 62 (delta 26), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (88/88), 23.41 KiB | 11.71 MiB/s, done.\n",
      "Resolving deltas: 100% (52/52), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf efdl_hw2\n",
    "!git clone https://github.com/tem-shett/efdl_hw2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T01:53:45.218882Z",
     "iopub.status.busy": "2026-02-16T01:53:45.218006Z",
     "iopub.status.idle": "2026-02-16T01:55:37.865168Z",
     "shell.execute_reply": "2026-02-16T01:55:37.864448Z",
     "shell.execute_reply.started": "2026-02-16T01:53:45.218830Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0216 01:53:46.966000 776 torch/distributed/run.py:774] \n",
      "W0216 01:53:46.966000 776 torch/distributed/run.py:774] *****************************************\n",
      "W0216 01:53:46.966000 776 torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0216 01:53:46.966000 776 torch/distributed/run.py:774] *****************************************\n",
      "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[rank1]:[W216 01:53:50.855240933 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.\n",
      "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[rank0]:[W216 01:53:51.908816391 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.\n",
      "loss: 4.244495993041992, acc: 0.07654\n",
      "Validation acc: 0.15780000388622284\n",
      "loss: 3.8400570361328126, acc: 0.13864\n",
      "Validation acc: 0.20989999175071716\n",
      "loss: 3.6136069750976563, acc: 0.1747\n",
      "Validation acc: 0.24169999361038208\n",
      "loss: 3.4361320831298827, acc: 0.20442\n",
      "Validation acc: 0.2653000056743622\n",
      "loss: 3.27998656829834, acc: 0.23072\n",
      "Validation acc: 0.28109997510910034\n",
      "loss: 3.1487765432739256, acc: 0.254\n",
      "Validation acc: 0.29019999504089355\n",
      "loss: 3.0283211712646483, acc: 0.2734\n",
      "Validation acc: 0.3165000081062317\n",
      "loss: 2.939554393005371, acc: 0.29094\n",
      "Validation acc: 0.3212999999523163\n",
      "loss: 2.8527548034667967, acc: 0.30544\n",
      "Validation acc: 0.3410000205039978\n",
      "loss: 2.7736188677978517, acc: 0.31946\n",
      "Rank=1 peak memory: 95.76171875MB\n",
      "Validation acc: 0.3456999957561493\n",
      "Rank=0 peak memory: 213.8388671875MB\n",
      "Time: 104.43176198005676\n",
      "[rank0]:[W216 01:55:36.932061953 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=2 efdl_hw2/ddp_cifar100_mine_with_valid.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
